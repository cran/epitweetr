
@article{fricker_comparing_2008,
	title = {Comparing syndromic surveillance detection methods: {EARS}' versus a {CUSUM}-based methodology},
	volume = {27},
	issn = {0277-6715},
	shorttitle = {Comparing syndromic surveillance detection methods},
	doi = {10.1002/sim.3197},
	abstract = {This paper compares the performance of three detection methods, entitled C1, C2, and C3, that are implemented in the early aberration reporting system (EARS) and other syndromic surveillance systems versus the CUSUM applied to model-based prediction errors. The cumulative sum (CUSUM) performed significantly better than the EARS' methods across all of the scenarios we evaluated. These scenarios consisted of various combinations of large and small background disease incidence rates, seasonal cycles from large to small (as well as no cycle), daily effects, and various types and levels of random daily variation. This leads us to recommend replacing the C1, C2, and C3 methods in existing syndromic surveillance systems with an appropriately implemented CUSUM method.},
	language = {eng},
	number = {17},
	journal = {Statistics in Medicine},
	author = {Fricker, Ronald D. and Hegler, Benjamin L. and Dunfee, David A.},
	month = jul,
	year = {2008},
	pmid = {18240128},
	keywords = {Humans, Population Surveillance, Regression Analysis, Computer Simulation, Disease Outbreaks, Bioterrorism, Epidemiologic Methods, Public Health Informatics, Syndrome},
	pages = {3407--3429},
	file = {Submitted Version:C\:\\Users\\esthe\\Zotero\\storage\\EDGZR7EQ\\Fricker et al. - 2008 - Comparing syndromic surveillance detection methods.pdf:application/pdf}
}

@article{salmon_monitoring_2016,
	title = {Monitoring {Count} {Time} {Series} in \textit{{R}} : {Aberration} {Detection} in {Public} {Health} {Surveillance}},
	volume = {70},
	issn = {1548-7660},
	shorttitle = {Monitoring {Count} {Time} {Series} in \textit{{R}}},
	url = {http://www.jstatsoft.org/v70/i10/},
	doi = {10.18637/jss.v070.i10},
	language = {en},
	number = {10},
	urldate = {2020-08-24},
	journal = {Journal of Statistical Software},
	author = {Salmon, Maëlle and Schumacher, Dirk and Höhle, Michael},
	year = {2016},
	file = {Full Text:C\:\\Users\\esthe\\Zotero\\storage\\IZ49LVH4\\Salmon et al. - 2016 - Monitoring Count Time Series in R  Aberrat.pdf:application/pdf}
}

@article{allevius_prospective_2017,
	title = {Prospective {Detection} of {Outbreaks}},
	url = {https://arxiv.org/abs/1711.08960},
	abstract = {This chapter surveys univariate and multivariate methods for infectious disease outbreak detection. The setting considered is a prospective one: data arrives sequentially as part of the surveillance systems maintained by public health authorities, and the task is to determine whether to 'sound the alarm' or not, given the recent history of data. The chapter begins by describing two popular detection methods for univariate time series data: the EARS algorithm of the CDC, and the Farrington algorithm more popular at European public health institutions. This is followed by a discussion of methods that extend some of the univariate methods to a multivariate setting. This may enable the detection of outbreaks whose signal is only weakly present in any single data stream considered on its own. The chapter ends with a longer discussion of methods for outbreak detection in spatio-temporal data. These methods are not only tasked with determining if and when an outbreak started to emerge, but also where. In particular, the scan statistics methodology for outbreak cluster detection in discrete-time area-referenced data is discussed, as well as similar methods for continuous-time, continuous-space data. As a running example to illustrate the methods covered in the chapter, a dataset on invasive meningococcal disease in Germany in the years 2002-2008 is used. This data and the methods covered are available through the R packages surveillance and scanstatistics.},
	urldate = {2020-08-24},
	journal = {arXiv:1711.08960 [stat]},
	author = {Allévius, Benjamin and Höhle, Michael},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.08960},
	keywords = {Statistics - Applications, Statistics - Methodology},
	annote = {Comment: This manuscript is a preprint of a chapter to appear in the Handbook of Infectious Disease Data Analysis, Held, L., Hens, N., O'Neill, P.D. and Wallinga, J. (Eds.). Chapman {\textbackslash}\& Hall/CRC, 2018. Please use the book for possible citations},
	file = {arXiv Fulltext PDF:C\:\\Users\\esthe\\Zotero\\storage\\P8PUTK5H\\Allévius and Höhle - 2017 - Prospective Detection of Outbreaks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\esthe\\Zotero\\storage\\CWC93447\\1711.html:text/html}
}

@article{farrington_statistical_1996,
	title = {A {Statistical} {Algorithm} for the {Early} {Detection} of {Outbreaks} of {Infectious} {Disease}},
	volume = {159},
	issn = {09641998},
	url = {https://www.jstor.org/stable/10.2307/2983331?origin=crossref},
	doi = {10.2307/2983331},
	number = {3},
	urldate = {2020-08-24},
	journal = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
	author = {Farrington, C. P. and Andrews, N. J. and Beale, A. D. and Catchpole, M. A.},
	year = {1996},
	pages = {547}
}

@book{chatterjee_sensitivity_1988,
	address = {New York},
	series = {Wiley series in probability and mathematical statistics},
	title = {Sensitivity analysis in linear regression},
	isbn = {978-0-471-82216-5},
	publisher = {Wiley},
	author = {Chatterjee, Samprit and Hadi, Ali S.},
	year = {1988},
	keywords = {Regression analysis, Mathematical optimization, Perturbation (Mathematics)},
	annote = {Includes index}
}

@article{noufaily_improved_2013,
	title = {An {Improved} {Algorithm} for {Outbreak} {Detection} in {Multiple} {Surveillance} {Systems}},
	volume = {5},
	issn = {1947-2579},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3692796/},
	abstract = {OBJECTIVE: To improve the performance of the England and Wales large scale multiple statistical surveillance system for infectious disease outbreaks with a view to reducing the number of false reports, while retaining good power to detect genuine outbreaks. INTRODUCTION: There has been much interest in the use of statistical surveillance systems over the last decade, prompted by concerns over bioterrorism, the emergence of new pathogens such as SARS and swine flu, and the persistent public health problems of infectious disease outbreaks. In the United Kingdom (UK), statistical surveillance methods have been in routine use at the Health Protection Agency (HPA) since the early 1990s and at Health Protection Scotland (HPS) since the early 2000s (1,2). These are based on a simple yet robust quasi-Poisson regression method (1). We revisit the algorithm with a view to improving its performance. METHODS: We fit a quasi-Poisson regression model to baseline data. One of the limitations of the current algorithm is the small number of baseline weeks used. We propose a simple seasonal adjustment using factors. We extend the model to include a 10-level factor. We fit the trend component always irrespective of its statistical significance. We are concerned that the existing weighting procedure is too drastic. The baseline at a certain week is down-weighted if the standardized Anscombe residual for that week is greater than 1. This condition was chosen empirically to avoid reducing the sensitivity of the system in the presence of large outbreaks in the baselines, but may be increasing the FPR unduly when there are no or only small outbreaks in the baselines. We investigate several other options, including reducing the down-weighting to cases where the Anscombe residuals are greater than 2 or 3. We evaluate a new re-weighting scheme informed by past decisions. Using this adaptive scheme, baseline data where an alarm was flagged are down-weighted to reduce their effect on current predictions. The criterion we use for re-weighting, here, is the value of the exceedance score. Finally, we investigate the validity of the upper threshold values based on the quasi-Poisson model when the data are generated using known negative binomial distributions. RESULTS: Our evaluation of the existing algorithm showed that the false positive rate (FPR) is too high. A novel feature of our new models is that they make use of much more baseline data. This resulted in a better estimation of the trend and variance and decreased the FPR. In addition, we found that the trend should always be fitted even when non-significant (or extreme). This decreases the discrepancies in the results when moving from one week to another. The adaptive reweighting scheme was found to give broadly equivalent results to the reweighting method based on scaled Anscombe residuals. Using the latter as in the original HPA method, but with much higher threshold for reweighting decreased the FPR further. Our investigations also suggest that the negative binomial model is a reasonable one, though not ideal in all circumstances. Thus, there is a good case for replacing the quasi-Poisson model with the negative binomial. One of the unusual features of the HPA system is that it is run every week on a database of more than 3300 distinct organisms, which is likely to produce a large number of aberrances. We found that retaining the exceedance score approach based on the 0.995 quantile is perfectly reasonable. This involves ranking aberrant organisms in order of exceedance. CONCLUSIONS: We have undertaken a thorough evaluation of the HPA’s outbreak detection system based on simulated and real data. The main conclusion from this evaluation is that the FPR is too high, owing to a combination of factors notably excessive down-weighting of high baselines and reliance on too few baseline weeks.},
	language = {eng},
	number = {1},
	journal = {Online Journal of Public Health Informatics},
	author = {Noufaily, Angela and Enki, Doyo and Farrington, Paddy and Garthwaite, Paul and Andrews, Nick and Charlett, Andre},
	month = apr,
	year = {2013},
	note = {Publisher: University of Illinois at Chicago Library},
	keywords = {negative binomial regression, outbreak, quasi-Poisson},
	pages = {e148}
}
